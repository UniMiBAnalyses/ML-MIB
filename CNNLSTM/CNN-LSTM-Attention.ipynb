{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "import os\n",
    "#from tqdm import tqdm\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Polygon, Circle, Rectangle\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import mplhep as hep\n",
    "#hep.set_style(hep.style.ROOT)\n",
    "hep.set_style(\"CMS\")\n",
    "#hep.set_style(\"ALICE\")\n",
    "#hep.set_style(\"firamath\")\n",
    "hep.set_style({\"font.sans-serif\":'Tex Gyre Heros'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path_name):\n",
    "    try:\n",
    "        os.mkdir(path_name)\n",
    "    except:\n",
    "        print(\"folder already there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-breakfast",
   "metadata": {},
   "source": [
    "# Preprare Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x, means, sigma):\n",
    "    for e_id in range(len(x)):\n",
    "        for j_id in range(len(x[e_id])):\n",
    "            x[e_id][j_id] = (x[e_id][j_id] - means) / sigma\n",
    "            \n",
    "            \n",
    "    return x\n",
    "\n",
    "\n",
    "def transform_back(x, means, sigma):\n",
    "    for e_id in range(len(x)):\n",
    "        for j_id in range(len(x[e_id])):\n",
    "            x[e_id][j_id] = x[e_id][j_id]* sigma + means\n",
    "              \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def Standardize(sam1):\n",
    "    \n",
    "    sam = deepcopy(sam1)\n",
    "    jets = []\n",
    "    for i in sam:\n",
    "        for j in i:\n",
    "            jets.append(j)\n",
    "            \n",
    "    jets = np.array(jets)\n",
    "    \n",
    "    means = jets.mean(axis=0)\n",
    "    sigma = jets.std(axis=0)\n",
    "    \n",
    "    for e_id in range(len(sam)):\n",
    "        for j_id in range(len(sam[e_id])):\n",
    "            sam[e_id][j_id] = (sam[e_id][j_id] - means) / sigma\n",
    "            \n",
    "    \n",
    "    return sam, means, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(sample):\n",
    "    weights = []\n",
    "    \n",
    "    for event in sample:\n",
    "        \n",
    "        sum_ = 0.1\n",
    "        if len(event) > 2:\n",
    "            sum_ += event[0][3] + event[1][3]\n",
    "        else:\n",
    "            sum_ += event[0][3]\n",
    "        \n",
    "        \n",
    "        weights.append(np.array(sum_))\n",
    "            \n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-excellence",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Concatenate, Conv1D, GlobalMaxPooling2D, Conv2D, Lambda, Layer, Reshape, LSTM, Permute, Dense,GlobalMaxPooling1D, MaxPooling1D,MaxPooling2D, TimeDistributed, Dropout, Bidirectional, BatchNormalization, Flatten\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialPyramidPooling(Layer):\n",
    "    '''Spatial pyramid pooling layer for 2D inputs.\n",
    "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
    "    K. He, X. Zhang, S. Ren, J. Sun\n",
    "    # Arguments\n",
    "        pool_list: list of int\n",
    "            List of pooling regions to use. The length of the list is the number of pooling regions,\n",
    "            each int in the list is the number of regions in that pool. For example [1,2,4] would be 3\n",
    "            regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n",
    "    # Output shape\n",
    "        2D tensor with shape:\n",
    "        `(samples, channels * sum([i * i for i in pool_list])`\n",
    "    '''\n",
    "\n",
    "    def __init__(self, pool_list, **kwargs):\n",
    "\n",
    "        self.dim_ordering = K.image_dim_ordering()\n",
    "        assert self.dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n",
    "\n",
    "        self.pool_list = pool_list\n",
    "\n",
    "        self.num_outputs_per_channel = sum([i * i for i in pool_list])\n",
    "\n",
    "        super(SpatialPyramidPooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            self.nb_channels = input_shape[1]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            self.nb_channels = input_shape[3]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.nb_channels * self.num_outputs_per_channel)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'pool_list': self.pool_list}\n",
    "        base_config = super(SpatialPyramidPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "\n",
    "        input_shape = K.shape(x)\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            num_rows = input_shape[2]\n",
    "            num_cols = input_shape[3]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            num_rows = input_shape[1]\n",
    "            num_cols = input_shape[2]\n",
    "\n",
    "        row_length = [K.cast(num_rows, 'float32') / i for i in self.pool_list]\n",
    "        col_length = [K.cast(num_cols, 'float32') / i for i in self.pool_list]\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
    "                for jy in range(num_pool_regions):\n",
    "                    for ix in range(num_pool_regions):\n",
    "                        x1 = ix * col_length[pool_num]\n",
    "                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n",
    "                        y1 = jy * row_length[pool_num]\n",
    "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
    "\n",
    "                        x1 = K.cast(K.round(x1), 'int32')\n",
    "                        x2 = K.cast(K.round(x2), 'int32')\n",
    "                        y1 = K.cast(K.round(y1), 'int32')\n",
    "                        y2 = K.cast(K.round(y2), 'int32')\n",
    "                        new_shape = [input_shape[0], input_shape[1],\n",
    "                                     y2 - y1, x2 - x1]\n",
    "                        x_crop = x[:, :, y1:y2, x1:x2]\n",
    "                        xm = K.reshape(x_crop, new_shape)\n",
    "                        pooled_val = K.max(xm, axis=(2, 3))\n",
    "                        outputs.append(pooled_val)\n",
    "\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
    "                for jy in range(num_pool_regions):\n",
    "                    for ix in range(num_pool_regions):\n",
    "                        x1 = ix * col_length[pool_num]\n",
    "                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n",
    "                        y1 = jy * row_length[pool_num]\n",
    "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
    "\n",
    "                        x1 = K.cast(K.round(x1), 'int32')\n",
    "                        x2 = K.cast(K.round(x2), 'int32')\n",
    "                        y1 = K.cast(K.round(y1), 'int32')\n",
    "                        y2 = K.cast(K.round(y2), 'int32')\n",
    "\n",
    "                        new_shape = [input_shape[0], y2 - y1,\n",
    "                                     x2 - x1, input_shape[3]]\n",
    "\n",
    "                        x_crop = x[:, y1:y2, x1:x2, :]\n",
    "                        xm = K.reshape(x_crop, new_shape)\n",
    "                        pooled_val = K.max(xm, axis=(1, 2))\n",
    "                        outputs.append(pooled_val)\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            outputs = K.concatenate(outputs)\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            # outputs = K.concatenate(outputs,axis = 1)\n",
    "            outputs = K.concatenate(outputs)\n",
    "            # outputs = K.reshape(outputs,(len(self.pool_list),self.num_outputs_per_channel,input_shape[0],input_shape[1]))\n",
    "            # outputs = K.permute_dimensions(outputs,(3,1,0,2))\n",
    "            outputs = K.reshape(outputs,(input_shape[0], self.num_outputs_per_channel * self.nb_channels))\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "    i = -1\n",
    "    while True:\n",
    "        i += 1  \n",
    "        if i == len(x_train): i = 0\n",
    "        \n",
    "        yield x_train[i], y_train[i], np.array([train_w[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_val():\n",
    "    \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "    i = -1\n",
    "    while True:\n",
    "        i += 1  \n",
    "        if i == len(x_test): i = 0\n",
    "        #print(x_test[i], y_test[i])\n",
    "        #print(x_test[i].shape, y_test[i].shape)\n",
    "        \n",
    "        yield x_test[i], y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_CNN():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=( None, 6))\n",
    "    \n",
    "    #extract features with 1D-CNN.. None refers to the variable number of jets per event\n",
    "    \n",
    "    conv_layer = Conv1D(64, 2, strides=1, padding=\"same\", activation='relu')(inputs) # output shape (None, 3, 32)\n",
    "    conv_layer_2 = Conv1D(128, 3, strides=1, padding=\"same\", activation='relu')(conv_layer) # output shape (None, 1, 64)\n",
    "    \n",
    "    pool = GlobalMaxPooling1D(data_format='channels_first')(conv_layer_2) # output shape (None, 1)\n",
    "    \n",
    "    \n",
    "    res = tf.expand_dims(pool, axis=2) #make \"N\" (None) timestamps each of one variable\n",
    "    \n",
    "    \n",
    "    lstm = LSTM(50, return_sequences=True, dropout=0.2, kernel_initializer=tf.keras.initializers.glorot_normal(seed=777), bias_initializer='zeros')\n",
    "    lstm = Bidirectional(lstm)(res)\n",
    "    \n",
    "    #Attention mechanism before output\n",
    "    \n",
    "    attention=TimeDistributed(Dense(1, activation = 'tanh'))(lstm)\n",
    "    attention=L.Softmax(axis=1)(attention)\n",
    "    context=L.Multiply()([attention,lstm])\n",
    "    cout=L.Lambda(lambda x: K.sum(x,axis=1))(context)\n",
    "    \n",
    "    #Sigmoid activated output\n",
    "    out = Dense(1, activation='sigmoid')(cout)\n",
    "    \n",
    "    model = Model(inputs, outputs=[out])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.00002), metrics=[tf.keras.metrics.PrecisionAtRecall(0.85, num_thresholds=100)])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001)\n",
    "history = model.fit(generate_data(), steps_per_epoch=len(x_train), epochs=100, callbacks = [callback],class_weight={0:4, 1:1}, validation_data=generate_val(), validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-xerox",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### mkdir(\"Pretrained\")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"Pretrained/CNNLSTM_CaloJetsPt30.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Pretrained/CNNLSTM_CaloJetsPt30.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-queen",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Concatenate, Conv1D, GlobalMaxPooling2D, Conv2D, Lambda, Layer, Reshape, LSTM, Permute, Dense,GlobalMaxPooling1D, MaxPooling1D,MaxPooling2D, TimeDistributed, Dropout, Bidirectional, BatchNormalization, Flatten\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D-CNN\n",
    "\n",
    "json_file = open('Pretrained/CNN2DLSTM_CaloJetsPt30.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"Pretrained/CNN2DLSTM_CaloJetsPt30.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-agenda",
   "metadata": {},
   "source": [
    "# Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='1D_LSTM_CNN_ptsort.pdf', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-drawing",
   "metadata": {},
   "source": [
    "# ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "y_pred_model = deepcopy(y_pred)\n",
    "\n",
    "y_pred_model = np.array([i[0][0] for i in y_pred_model])\n",
    "\n",
    "fpr_keras_dnn, tpr_keras_dnn, thresholds_keras_dnn = roc_curve(y_test, y_pred_model)\n",
    "auc_keras_dnn = auc(fpr_keras_dnn, tpr_keras_dnn)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras_dnn, tpr_keras_dnn, 'r', label='auc_keras_dnn  (area = {:.3f})'.format(auc_keras_dnn))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-mobile",
   "metadata": {},
   "source": [
    "# Plotting Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import mplhep as hep\n",
    "#hep.set_style(hep.style.ROOT)\n",
    "hep.set_style(\"CMS\")\n",
    "#hep.set_style(\"ALICE\")\n",
    "#hep.set_style(\"firamath\")\n",
    "hep.set_style({\"font.sans-serif\":'Tex Gyre Heros'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attention(sam, val, y, p):\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(10, 10), dpi = 160)\n",
    "    plot = []\n",
    "\n",
    "    for j in sam:\n",
    "        #plot.append([j]*6)\n",
    "        plot.append([j]*4)\n",
    "        \n",
    "    \n",
    "    val = val[::-1]\n",
    "\n",
    "    #im = ax.imshow(plot,cmap=plt.get_cmap('Purples'), alpha=0.7, extent = [0, 6, 0, len(plot)])\n",
    "    im = ax.imshow(plot,cmap=plt.get_cmap('Purples'), alpha=0.7, extent = [0, 4, 0, len(plot)])\n",
    "    #ax.set_xticklabels([r\"$p_T$\", r\"$\\eta$\", r\"$\\phi$\", r\"$btag$\", r\"$m_j$\", r\"$E$\"])\n",
    "    ax.set_xticklabels([r\"$p_T$\", r\"$\\eta$\", r\"$\\phi$\", r\"$btag$\"])\n",
    "    #xlabel = [r\"$p_T$\", r\"$\\eta$\", r\"$\\phi$\", r\"$btag$\", r\"$m_j$\", r\"$E$\"]\n",
    "    xlabel = [r\"$p_T$\", r\"$\\eta$\", r\"$\\phi$\", r\"$btag$\"]\n",
    "    #ax.set_xticks(np.arange(0.5, 6.5,1))\n",
    "    ax.set_xticks(np.arange(0.5, 4.5,1))\n",
    "    ax.set_yticks(np.arange(0.5,len(plot)+0.5,1))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(xlabel)\n",
    "    ax.set_yticklabels(np.arange(len(plot)))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    cb = fig.colorbar(im, fraction=0.046, pad=0.04, cax=cax)\n",
    "    \n",
    "    cb.ax.set_yticklabels([ round(i, 2) for i in np.arange(min(sam), max(sam), (max(sam)-min(sam))/10)], fontsize=20)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "    \n",
    "    half = 0.8*max(sam)\n",
    "    \n",
    "    print(half, max(sam))\n",
    "    \n",
    "    \n",
    "    for i in range(len(val)):\n",
    "        #for j in range(0,6):\n",
    "        for j in range(0,4):\n",
    "            #text = ax.text(j+0.5, i+0.5, \"%.2f\" % val[i, j],\n",
    "                           #ha=\"center\", va=\"center\", color=\"black\", size= 15)\n",
    "                \n",
    "            if sam[::-1][i] < half:\n",
    "                text = ax.text(j+0.5, i+0.5, \"%.2f\" % val[i][j],\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", size= 20)\n",
    "            else:\n",
    "                print(sam[::-1][i], half)\n",
    "                text = ax.text(j+0.5, i+0.5, \"%.2f\" % val[i][j],\n",
    "                               ha=\"center\", va=\"center\", color=\"white\", size= 20)\n",
    "                \n",
    "    if y == 0:\n",
    "        t = \"Class QCD Background\"\n",
    "    else:\n",
    "        t = r\"Class $HH\\rightarrow 4b$\"\n",
    "        \n",
    "    t += r\"  $P ( C=HH\\rightarrow 4b | X )$ = \" + \"%.3f\" % p[0][0]\n",
    "    \n",
    "    ax.text(0, len(plot) + 0.07, t, size=20)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it gets the output of a llayer called \"softmax\". These are the attention weifghts we want to plot\n",
    "grad_model = Model([model.inputs], \n",
    "                   [model.get_layer(\"softmax\").output])\n",
    "\n",
    "\n",
    "# divide attention score for signal and bkg events\n",
    "atts_sig = []\n",
    "preds_sig = []\n",
    "\n",
    "\n",
    "# extract 10 signal pred\n",
    "j = 0\n",
    "for i in range(1000):\n",
    "    \n",
    "    if y_test[i] != 1: continue\n",
    "    else:\n",
    "        \n",
    "        # use grad_model to get the attention score for this event\n",
    "        atts_sig.append(grad_model.predict(x_test[i])[0])\n",
    "        # use full model to get the posterior prob.\n",
    "        preds_sig.append(model.predict(x_test[i]))\n",
    "        j+= 1\n",
    "    # just save 10 events\n",
    "    if j == 10: break\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "# Do the same for bkg\n",
    "\n",
    "atts_bkg = []\n",
    "preds_bkg = []\n",
    "j = 0\n",
    "for i in range(1000):\n",
    "    if y_test[i] != 0: continue\n",
    "    else:\n",
    "        atts_bkg.append(grad_model.predict(x_test[i])[0])\n",
    "        preds_bkg.append(model.predict(x_test[i]))\n",
    "        j+=1\n",
    "    if j == 10: break\n",
    "        \n",
    "print(\"done\")      \n",
    "atts = []\n",
    "preds = []\n",
    "\n",
    "\n",
    "\n",
    "# collect 100000 of them \n",
    "\n",
    "#for i in range(len(x_test)):\n",
    "for i in range(10000):\n",
    "    \n",
    "    if i % 100 == 0: print(float(i) / 10000 * 100)\n",
    "    \n",
    "    \n",
    "    atts.append(grad_model.predict(x_test[i])[0])\n",
    "    preds.append(model.predict(x_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape attention scores in order to plot the color map with imshow\n",
    "\n",
    "c = []\n",
    "\n",
    "for i in range(len(atts)):\n",
    "    n = atts[i].reshape(atts[i].shape[0])\n",
    "    c.append(n)\n",
    "\n",
    "# c is the new array of attention scores\n",
    "c = np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot attention score overlayd with the event image\n",
    "# only for 100 events\n",
    "# and only for bkg events (y_test == 0)\n",
    "# and only if the model predicts a signal class\n",
    "# Meaning this examples are false positives\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "while 1:\n",
    "    if preds[i] > 0.85 and y_test[i] == 0:\n",
    "        fig = show_attention(c[i], X_test[i][0], y_test[i], preds[i])\n",
    "        fig.savefig(\"Attention/high/QCD_{}.pdf\".format(i))\n",
    "        j+=1 \n",
    "    i+= 1\n",
    "    if j == 100: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
